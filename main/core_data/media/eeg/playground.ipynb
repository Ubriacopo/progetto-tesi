{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from main.dataset.amigos import load_participant_data\n",
    "from main.dataset.amigos.config import AmigosConfig\n",
    "import mne.io\n",
    "\n",
    "from main.core_data.media.eeg import EEGFeatureExtractor\n",
    "\n",
    "info = mne.create_info(\n",
    "    ch_names=AmigosConfig.CH_NAMES,\n",
    "    ch_types=AmigosConfig.CH_TYPES,\n",
    "    sfreq=AmigosConfig.original_eeg_fs\n",
    ")\n",
    "participant_data = load_participant_data(Path(\"../../../resources/AMIGOS/pre_processed_py/\"))\n",
    "eeg_data = participant_data[\"P01\"][\"joined_data\"][0]\n",
    "raw = mne.io.RawArray(eeg_data.T, info=info, verbose=False)"
   ],
   "id": "eb96df96e8ffe1ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "extractor = EEGFeatureExtractor(raw)\n",
    "starts = extractor.pick_segments(\n",
    "    4, 0.125, bands=((4, 8), (8, 13), (13, 30)), band_weights=(0.4, 0.5, 0.4)\n",
    ")"
   ],
   "id": "b34bb761b6910765",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from main.core_data.sampler import EegFeaturesAndRandLogUIntervalsSegmenter\n",
    "\n",
    "feat_seg = EegFeaturesAndRandLogUIntervalsSegmenter(\n",
    "    min_length=1,\n",
    "    max_length=30,\n",
    "    num_segments=20,\n",
    "    extraction_jitter=0,\n",
    "    anchor_identification_hop=0.125\n",
    ")"
   ],
   "id": "f8c4fd87515ef2be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from main.core_data.media.eeg import EEG\n",
    "import numpy as np\n",
    "\n",
    "r = feat_seg.compute_segments(EEG(data=raw, eid=\"1\", fs=128))\n",
    "a = np.array(r)\n",
    "\n",
    "np.diff(a)"
   ],
   "id": "48f5f1d70ea89e93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a",
   "id": "c25525d4e1db6ab7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Total coverage:\n",
    "unique_coverage = 0\n",
    "duration = raw.duration\n",
    "\n",
    "taken_quarter_seconds = np.array([0 for i in range(int(duration * 4))])\n",
    "for start, stop in a:\n",
    "    start = int(start * 4)\n",
    "    stop = int(stop * 4)\n",
    "    taken_quarter_seconds[start:stop] += 1\n",
    "\n",
    "unique_coverage = len(taken_quarter_seconds[taken_quarter_seconds > 0]) / (raw.duration * 4)\n",
    "print(unique_coverage)  # We use 95% of the original signal"
   ],
   "id": "b5d1f0b2837a98d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Coverage of SHORT segments:\n",
    "unique_coverage = 0\n",
    "duration = raw.duration\n",
    "\n",
    "taken_quarter_seconds = np.array([0 for i in range(int(duration * 4))])\n",
    "for start, stop in a[a[:, 1] - a[:, 0] < 4.1]:\n",
    "    start = int(start * 4)\n",
    "    stop = int(stop * 4)\n",
    "    taken_quarter_seconds[start:stop] += 1\n",
    "\n",
    "unique_coverage = len(taken_quarter_seconds[taken_quarter_seconds > 0]) / (raw.duration * 4)\n",
    "print(unique_coverage)  # We use 95% of the original signal"
   ],
   "id": "58df6a17cc15b22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:58:00.361658Z",
     "start_time": "2025-10-26T14:57:57.047752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from braindecode.models import Labram\n",
    "\n",
    "model = Labram(input_window_seconds=15, sfreq=200, n_chans=64, n_outputs=1)"
   ],
   "id": "2e7eb8360d4a8dc8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:58:00.992350Z",
     "start_time": "2025-10-26T14:58:00.907506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "ckpt = torch.load(\"../../../dependencies/labram-base.pth\", map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "# 1) Extract the actual state dict\n",
    "sd = ckpt.get(\"state_dict\", ckpt.get(\"model\", ckpt))\n",
    "assert isinstance(sd, (dict, OrderedDict)), \"No model/state_dict found in checkpoint.\"\n",
    "\n",
    "# 2) Optional: normalize key names (extend as needed)\n",
    "ALIASES = {\n",
    "    \"pos_embed\": \"position_embedding\",\n",
    "    \"time_embed\": \"temporal_embedding\",\n",
    "    \"head.weight\": \"final_layer.weight\",\n",
    "    \"head.bias\": \"final_layer.bias\",\n",
    "    \"norm.weight\": \"fc_norm.weight\",\n",
    "    \"norm.bias\": \"fc_norm.bias\",\n",
    "}\n",
    "\n",
    "\n",
    "def normalize(k: str) -> str:\n",
    "    k = k.removeprefix(\"module.\").removeprefix(\"backbone.\").removeprefix(\"encoder.\")\n",
    "    # simple alias swaps\n",
    "    for a, b in ALIASES.items():\n",
    "        if k == a or k.endswith(\".\" + a):\n",
    "            k = k[: -len(a)] + b if k.endswith(\".\" + a) else b\n",
    "    return k\n",
    "\n",
    "\n",
    "# 3) Per-layer copy: only load keys that exist and match shape\n",
    "model_sd = model.state_dict()\n",
    "to_load = {}\n",
    "loaded, skipped, shape_mismatch = [], [], []\n",
    "\n",
    "for k, w in sd.items():\n",
    "    nk = normalize(k)\n",
    "    if nk in model_sd:\n",
    "        if model_sd[nk].shape == w.shape:\n",
    "            to_load[nk] = w\n",
    "            loaded.append(nk)\n",
    "        else:\n",
    "            shape_mismatch.append((nk, tuple(w.shape), tuple(model_sd[nk].shape)))\n",
    "    else:\n",
    "        skipped.append(k)\n",
    "\n",
    "# 4) Load the matching subset (strict=False), report the rest\n",
    "incompat = model.load_state_dict(to_load, strict=False)\n",
    "print(f\"Loaded {len(loaded)} layers\")\n",
    "if incompat.missing_keys: print(\"Missing in model:\", incompat.missing_keys[:10], \"...\")\n",
    "if incompat.unexpected_keys: print(\"Unexpected in ckpt (after mapping):\", incompat.unexpected_keys[:10], \"...\")\n",
    "if shape_mismatch: print(\"Shape mismatches:\", shape_mismatch[:10], \"...\")\n"
   ],
   "id": "1686ed771d2f70c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 layers\n",
      "Missing in model: ['cls_token', 'position_embedding', 'temporal_embedding', 'patch_embed.segment_patch.patcher.weight', 'patch_embed.segment_patch.patcher.bias', 'patch_embed.temporal_conv.conv1.weight', 'patch_embed.temporal_conv.conv1.bias', 'patch_embed.temporal_conv.norm1.weight', 'patch_embed.temporal_conv.norm1.bias', 'patch_embed.temporal_conv.conv2.weight'] ...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:58:01.749710Z",
     "start_time": "2025-10-26T14:58:01.744226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# map checkpoint_key -> model_key\n",
    "model.mapping = {\n",
    "    \"pos_embed\": \"position_embedding\",\n",
    "    \"time_embed\": \"temporal_embedding\",\n",
    "    \"head.weight\": \"final_layer.weight\",\n",
    "    \"head.bias\": \"final_layer.bias\",\n",
    "    \"norm.weight\": \"fc_norm.weight\",\n",
    "    \"norm.bias\": \"fc_norm.bias\",\n",
    "    # add more as needed\n",
    "}\n",
    "model.load_state_dict(sd, strict=False)"
   ],
   "id": "a009b2febc9f0395",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['cls_token', 'position_embedding', 'temporal_embedding', 'patch_embed.segment_patch.patcher.weight', 'patch_embed.segment_patch.patcher.bias', 'patch_embed.temporal_conv.conv1.weight', 'patch_embed.temporal_conv.conv1.bias', 'patch_embed.temporal_conv.norm1.weight', 'patch_embed.temporal_conv.norm1.bias', 'patch_embed.temporal_conv.conv2.weight', 'patch_embed.temporal_conv.conv2.bias', 'patch_embed.temporal_conv.norm2.weight', 'patch_embed.temporal_conv.norm2.bias', 'patch_embed.temporal_conv.conv3.weight', 'patch_embed.temporal_conv.conv3.bias', 'patch_embed.temporal_conv.norm3.weight', 'patch_embed.temporal_conv.norm3.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.0.weight', 'blocks.0.mlp.0.bias', 'blocks.0.mlp.2.weight', 'blocks.0.mlp.2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.0.weight', 'blocks.1.mlp.0.bias', 'blocks.1.mlp.2.weight', 'blocks.1.mlp.2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.0.weight', 'blocks.2.mlp.0.bias', 'blocks.2.mlp.2.weight', 'blocks.2.mlp.2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.0.weight', 'blocks.3.mlp.0.bias', 'blocks.3.mlp.2.weight', 'blocks.3.mlp.2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.0.weight', 'blocks.4.mlp.0.bias', 'blocks.4.mlp.2.weight', 'blocks.4.mlp.2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.0.weight', 'blocks.5.mlp.0.bias', 'blocks.5.mlp.2.weight', 'blocks.5.mlp.2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.0.weight', 'blocks.6.mlp.0.bias', 'blocks.6.mlp.2.weight', 'blocks.6.mlp.2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.0.weight', 'blocks.7.mlp.0.bias', 'blocks.7.mlp.2.weight', 'blocks.7.mlp.2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.0.weight', 'blocks.8.mlp.0.bias', 'blocks.8.mlp.2.weight', 'blocks.8.mlp.2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.0.weight', 'blocks.9.mlp.0.bias', 'blocks.9.mlp.2.weight', 'blocks.9.mlp.2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.0.weight', 'blocks.10.mlp.0.bias', 'blocks.10.mlp.2.weight', 'blocks.10.mlp.2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.0.weight', 'blocks.11.mlp.0.bias', 'blocks.11.mlp.2.weight', 'blocks.11.mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'final_layer.weight', 'final_layer.bias'], unexpected_keys=['logit_scale', 'student.cls_token', 'student.mask_token', 'student.pos_embed', 'student.time_embed', 'student.patch_embed.conv1.weight', 'student.patch_embed.conv1.bias', 'student.patch_embed.norm1.weight', 'student.patch_embed.norm1.bias', 'student.patch_embed.conv2.weight', 'student.patch_embed.conv2.bias', 'student.patch_embed.norm2.weight', 'student.patch_embed.norm2.bias', 'student.patch_embed.conv3.weight', 'student.patch_embed.conv3.bias', 'student.patch_embed.norm3.weight', 'student.patch_embed.norm3.bias', 'student.blocks.0.gamma_1', 'student.blocks.0.gamma_2', 'student.blocks.0.norm1.weight', 'student.blocks.0.norm1.bias', 'student.blocks.0.attn.qkv.weight', 'student.blocks.0.attn.q_norm.weight', 'student.blocks.0.attn.q_norm.bias', 'student.blocks.0.attn.k_norm.weight', 'student.blocks.0.attn.k_norm.bias', 'student.blocks.0.attn.proj.weight', 'student.blocks.0.attn.proj.bias', 'student.blocks.0.norm2.weight', 'student.blocks.0.norm2.bias', 'student.blocks.0.mlp.fc1.weight', 'student.blocks.0.mlp.fc1.bias', 'student.blocks.0.mlp.fc2.weight', 'student.blocks.0.mlp.fc2.bias', 'student.blocks.1.gamma_1', 'student.blocks.1.gamma_2', 'student.blocks.1.norm1.weight', 'student.blocks.1.norm1.bias', 'student.blocks.1.attn.qkv.weight', 'student.blocks.1.attn.q_norm.weight', 'student.blocks.1.attn.q_norm.bias', 'student.blocks.1.attn.k_norm.weight', 'student.blocks.1.attn.k_norm.bias', 'student.blocks.1.attn.proj.weight', 'student.blocks.1.attn.proj.bias', 'student.blocks.1.norm2.weight', 'student.blocks.1.norm2.bias', 'student.blocks.1.mlp.fc1.weight', 'student.blocks.1.mlp.fc1.bias', 'student.blocks.1.mlp.fc2.weight', 'student.blocks.1.mlp.fc2.bias', 'student.blocks.2.gamma_1', 'student.blocks.2.gamma_2', 'student.blocks.2.norm1.weight', 'student.blocks.2.norm1.bias', 'student.blocks.2.attn.qkv.weight', 'student.blocks.2.attn.q_norm.weight', 'student.blocks.2.attn.q_norm.bias', 'student.blocks.2.attn.k_norm.weight', 'student.blocks.2.attn.k_norm.bias', 'student.blocks.2.attn.proj.weight', 'student.blocks.2.attn.proj.bias', 'student.blocks.2.norm2.weight', 'student.blocks.2.norm2.bias', 'student.blocks.2.mlp.fc1.weight', 'student.blocks.2.mlp.fc1.bias', 'student.blocks.2.mlp.fc2.weight', 'student.blocks.2.mlp.fc2.bias', 'student.blocks.3.gamma_1', 'student.blocks.3.gamma_2', 'student.blocks.3.norm1.weight', 'student.blocks.3.norm1.bias', 'student.blocks.3.attn.qkv.weight', 'student.blocks.3.attn.q_norm.weight', 'student.blocks.3.attn.q_norm.bias', 'student.blocks.3.attn.k_norm.weight', 'student.blocks.3.attn.k_norm.bias', 'student.blocks.3.attn.proj.weight', 'student.blocks.3.attn.proj.bias', 'student.blocks.3.norm2.weight', 'student.blocks.3.norm2.bias', 'student.blocks.3.mlp.fc1.weight', 'student.blocks.3.mlp.fc1.bias', 'student.blocks.3.mlp.fc2.weight', 'student.blocks.3.mlp.fc2.bias', 'student.blocks.4.gamma_1', 'student.blocks.4.gamma_2', 'student.blocks.4.norm1.weight', 'student.blocks.4.norm1.bias', 'student.blocks.4.attn.qkv.weight', 'student.blocks.4.attn.q_norm.weight', 'student.blocks.4.attn.q_norm.bias', 'student.blocks.4.attn.k_norm.weight', 'student.blocks.4.attn.k_norm.bias', 'student.blocks.4.attn.proj.weight', 'student.blocks.4.attn.proj.bias', 'student.blocks.4.norm2.weight', 'student.blocks.4.norm2.bias', 'student.blocks.4.mlp.fc1.weight', 'student.blocks.4.mlp.fc1.bias', 'student.blocks.4.mlp.fc2.weight', 'student.blocks.4.mlp.fc2.bias', 'student.blocks.5.gamma_1', 'student.blocks.5.gamma_2', 'student.blocks.5.norm1.weight', 'student.blocks.5.norm1.bias', 'student.blocks.5.attn.qkv.weight', 'student.blocks.5.attn.q_norm.weight', 'student.blocks.5.attn.q_norm.bias', 'student.blocks.5.attn.k_norm.weight', 'student.blocks.5.attn.k_norm.bias', 'student.blocks.5.attn.proj.weight', 'student.blocks.5.attn.proj.bias', 'student.blocks.5.norm2.weight', 'student.blocks.5.norm2.bias', 'student.blocks.5.mlp.fc1.weight', 'student.blocks.5.mlp.fc1.bias', 'student.blocks.5.mlp.fc2.weight', 'student.blocks.5.mlp.fc2.bias', 'student.blocks.6.gamma_1', 'student.blocks.6.gamma_2', 'student.blocks.6.norm1.weight', 'student.blocks.6.norm1.bias', 'student.blocks.6.attn.qkv.weight', 'student.blocks.6.attn.q_norm.weight', 'student.blocks.6.attn.q_norm.bias', 'student.blocks.6.attn.k_norm.weight', 'student.blocks.6.attn.k_norm.bias', 'student.blocks.6.attn.proj.weight', 'student.blocks.6.attn.proj.bias', 'student.blocks.6.norm2.weight', 'student.blocks.6.norm2.bias', 'student.blocks.6.mlp.fc1.weight', 'student.blocks.6.mlp.fc1.bias', 'student.blocks.6.mlp.fc2.weight', 'student.blocks.6.mlp.fc2.bias', 'student.blocks.7.gamma_1', 'student.blocks.7.gamma_2', 'student.blocks.7.norm1.weight', 'student.blocks.7.norm1.bias', 'student.blocks.7.attn.qkv.weight', 'student.blocks.7.attn.q_norm.weight', 'student.blocks.7.attn.q_norm.bias', 'student.blocks.7.attn.k_norm.weight', 'student.blocks.7.attn.k_norm.bias', 'student.blocks.7.attn.proj.weight', 'student.blocks.7.attn.proj.bias', 'student.blocks.7.norm2.weight', 'student.blocks.7.norm2.bias', 'student.blocks.7.mlp.fc1.weight', 'student.blocks.7.mlp.fc1.bias', 'student.blocks.7.mlp.fc2.weight', 'student.blocks.7.mlp.fc2.bias', 'student.blocks.8.gamma_1', 'student.blocks.8.gamma_2', 'student.blocks.8.norm1.weight', 'student.blocks.8.norm1.bias', 'student.blocks.8.attn.qkv.weight', 'student.blocks.8.attn.q_norm.weight', 'student.blocks.8.attn.q_norm.bias', 'student.blocks.8.attn.k_norm.weight', 'student.blocks.8.attn.k_norm.bias', 'student.blocks.8.attn.proj.weight', 'student.blocks.8.attn.proj.bias', 'student.blocks.8.norm2.weight', 'student.blocks.8.norm2.bias', 'student.blocks.8.mlp.fc1.weight', 'student.blocks.8.mlp.fc1.bias', 'student.blocks.8.mlp.fc2.weight', 'student.blocks.8.mlp.fc2.bias', 'student.blocks.9.gamma_1', 'student.blocks.9.gamma_2', 'student.blocks.9.norm1.weight', 'student.blocks.9.norm1.bias', 'student.blocks.9.attn.qkv.weight', 'student.blocks.9.attn.q_norm.weight', 'student.blocks.9.attn.q_norm.bias', 'student.blocks.9.attn.k_norm.weight', 'student.blocks.9.attn.k_norm.bias', 'student.blocks.9.attn.proj.weight', 'student.blocks.9.attn.proj.bias', 'student.blocks.9.norm2.weight', 'student.blocks.9.norm2.bias', 'student.blocks.9.mlp.fc1.weight', 'student.blocks.9.mlp.fc1.bias', 'student.blocks.9.mlp.fc2.weight', 'student.blocks.9.mlp.fc2.bias', 'student.blocks.10.gamma_1', 'student.blocks.10.gamma_2', 'student.blocks.10.norm1.weight', 'student.blocks.10.norm1.bias', 'student.blocks.10.attn.qkv.weight', 'student.blocks.10.attn.q_norm.weight', 'student.blocks.10.attn.q_norm.bias', 'student.blocks.10.attn.k_norm.weight', 'student.blocks.10.attn.k_norm.bias', 'student.blocks.10.attn.proj.weight', 'student.blocks.10.attn.proj.bias', 'student.blocks.10.norm2.weight', 'student.blocks.10.norm2.bias', 'student.blocks.10.mlp.fc1.weight', 'student.blocks.10.mlp.fc1.bias', 'student.blocks.10.mlp.fc2.weight', 'student.blocks.10.mlp.fc2.bias', 'student.blocks.11.gamma_1', 'student.blocks.11.gamma_2', 'student.blocks.11.norm1.weight', 'student.blocks.11.norm1.bias', 'student.blocks.11.attn.qkv.weight', 'student.blocks.11.attn.q_norm.weight', 'student.blocks.11.attn.q_norm.bias', 'student.blocks.11.attn.k_norm.weight', 'student.blocks.11.attn.k_norm.bias', 'student.blocks.11.attn.proj.weight', 'student.blocks.11.attn.proj.bias', 'student.blocks.11.norm2.weight', 'student.blocks.11.norm2.bias', 'student.blocks.11.mlp.fc1.weight', 'student.blocks.11.mlp.fc1.bias', 'student.blocks.11.mlp.fc2.weight', 'student.blocks.11.mlp.fc2.bias', 'student.norm.weight', 'student.norm.bias', 'student.lm_head.weight', 'student.lm_head.bias', 'lm_head.weight', 'lm_head.bias', 'projection_head.0.weight', 'projection_head.0.bias'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:59:30.185210Z",
     "start_time": "2025-10-26T14:59:30.111102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to('cuda')\n",
    "o = model(torch.randn(2, 64, 400).to('cuda'), return_all_tokens=True)"
   ],
   "id": "5bd5e1ecb8fc4311",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (129) must match the size of tensor b (961) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m model.to(\u001B[33m'\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m o = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandn\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m400\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcuda\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_all_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/braindecode/models/labram.py:469\u001B[39m, in \u001B[36mLabram.forward\u001B[39m\u001B[34m(self, x, input_chans, return_patch_tokens, return_all_tokens)\u001B[39m\n\u001B[32m    442\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    443\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    444\u001B[39m     x,\n\u001B[32m   (...)\u001B[39m\u001B[32m    447\u001B[39m     return_all_tokens=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    448\u001B[39m ):\n\u001B[32m    449\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    450\u001B[39m \u001B[33;03m    Forward the input EEG data through the model.\u001B[39;00m\n\u001B[32m    451\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    467\u001B[39m \u001B[33;03m        The output of the model with dimensions (batch, n_outputs)\u001B[39;00m\n\u001B[32m    468\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m469\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforward_features\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    470\u001B[39m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    471\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_chans\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_chans\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    472\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_patch_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_patch_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    473\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_all_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_all_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    474\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    475\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.final_layer(x)\n\u001B[32m    476\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/braindecode/models/labram.py:410\u001B[39m, in \u001B[36mLabram.forward_features\u001B[39m\u001B[34m(self, x, input_chans, return_patch_tokens, return_all_tokens)\u001B[39m\n\u001B[32m    406\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.position_embedding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    407\u001B[39m     pos_embed = \u001B[38;5;28mself\u001B[39m._adj_position_embedding(\n\u001B[32m    408\u001B[39m         pos_embed_used=pos_embed_used, batch_size=batch_size\n\u001B[32m    409\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m410\u001B[39m     \u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_embed\u001B[49m\n\u001B[32m    412\u001B[39m \u001B[38;5;66;03m# The time embedding is added across the channels after the [CLS] token\u001B[39;00m\n\u001B[32m    413\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.neural_tokenizer:\n",
      "\u001B[31mRuntimeError\u001B[39m: The size of tensor a (129) must match the size of tensor b (961) at non-singleton dimension 1"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:58:10.445417Z",
     "start_time": "2025-10-26T14:58:10.442682Z"
    }
   },
   "cell_type": "code",
   "source": "o.shape",
   "id": "f9056b1e28098f5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 961, 200])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:58:06.876909Z",
     "start_time": "2025-10-26T14:58:06.874833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "model.final_layer = nn.Identity()"
   ],
   "id": "8ff42346ac6c43c2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model",
   "id": "eb78bf8ae8f833bf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
