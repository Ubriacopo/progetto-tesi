{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T15:33:04.898528Z",
     "start_time": "2025-04-28T15:33:04.358886Z"
    }
   },
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_path = hf_hub_download(repo_id=\"wenhuic/Neuro-GPT\", filename=\"pretrained_model/pytorch_model.bin\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studenti/fichera/progetto-tesi/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T15:33:10.060791Z",
     "start_time": "2025-04-28T15:33:04.906926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Weights of the pre-trained model\n",
    "model = torch.load(model_path, weights_only=False)"
   ],
   "id": "38c3b48c5f4133d0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T15:33:14.813455Z",
     "start_time": "2025-04-28T15:33:10.798033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from NeuroGPT.src.model import Model\n",
    "\n",
    "from NeuroGPT.src.decoder.make_decoder import make_decoder\n",
    "from NeuroGPT.src.decoder.unembedder import make_unembedder\n",
    "from NeuroGPT.src.embedder.make import make_embedder\n",
    "\n",
    "Model(None, make_embedder(), make_decoder(), make_unembedder()).from_pretrained(model_path)"
   ],
   "id": "36f8c4e519c555d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/studenti/fichera/.cache/huggingface/hub/models--wenhuic--Neuro-GPT/snapshots/2e0b940580db95e6237227c27c13b2319909d0fc/pretrained_model/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "embedder.msk_embed shape mismatch between pretrained model and current model torch.Size([1, 1, 1080]) vs torch.Size([1, 1, 1024])",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mNeuroGPT\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdecoder\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01munembedder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m make_unembedder\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mNeuroGPT\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01membedder\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmake\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m make_embedder\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmake_embedder\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmake_decoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmake_unembedder\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/progetto-tesi/NeuroGPT/src/model.py:71\u001B[39m, in \u001B[36mModel.from_pretrained\u001B[39m\u001B[34m(self, pretrained_path)\u001B[39m\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state_dict():\n\u001B[32m     70\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m pretrained:\n\u001B[32m---> \u001B[39m\u001B[32m71\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m pretrained[k].shape == \u001B[38;5;28mself\u001B[39m.state_dict()[k].shape,\\\n\u001B[32m     72\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m shape mismatch between pretrained model and current model \u001B[39m\u001B[33m'\u001B[39m+\\\n\u001B[32m     73\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained[k].shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m vs \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.state_dict()[k].shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\n\u001B[32m     75\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m pretrained:     \n\u001B[32m     76\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state_dict():\n",
      "\u001B[31mAssertionError\u001B[39m: embedder.msk_embed shape mismatch between pretrained model and current model torch.Size([1, 1, 1080]) vs torch.Size([1, 1, 1024])"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T16:33:49.671076Z",
     "start_time": "2025-05-07T16:33:49.667042Z"
    }
   },
   "cell_type": "code",
   "source": "## NeuroGPT",
   "id": "747018e8df4d270a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37bea6f67c7b44c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BrainBERT",
   "id": "762c1cc253a29230"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:26:28.715512Z",
     "start_time": "2025-05-07T17:26:28.710075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"BrainBERT_HOME\"] = \"dependencies.BrainBERT.\""
   ],
   "id": "ad0bbccd41169d94",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:26:31.264174Z",
     "start_time": "2025-05-07T17:26:29.301592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dependencies.BrainBERT.models as models\n",
    "from omegaconf import OmegaConf\n",
    "import torch"
   ],
   "id": "a05d00274d4e651c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:26:33.065646Z",
     "start_time": "2025-05-07T17:26:33.059559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model(cfg):\n",
    "    ckpt_path = cfg.upstream_ckpt\n",
    "    init_state = torch.load(ckpt_path, weights_only=False)\n",
    "    upstream_cfg = init_state[\"model_cfg\"]\n",
    "    upstream = models.build_model(upstream_cfg)\n",
    "    return upstream\n",
    "\n",
    "\n",
    "def load_model_weights(model, states, multi_gpu):\n",
    "    if multi_gpu:\n",
    "        model.module.load_weights(states)\n",
    "    else:\n",
    "        model.load_weights(states)\n"
   ],
   "id": "cd94fabb32d9ad25",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:27:06.835099Z",
     "start_time": "2025-05-07T17:27:05.734481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt_path = \"../dependencies/BrainBERT_weights/stft_large_pretrained.pth\"\n",
    "cfg = OmegaConf.create({\"upstream_ckpt\": ckpt_path})\n",
    "\n",
    "model = build_model(cfg)\n",
    "model.to('cuda')\n",
    "\n",
    "init_state = torch.load(ckpt_path, weights_only=False)\n",
    "load_model_weights(model, init_state['model'], False)"
   ],
   "id": "eae941954cbac1ce",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:10:03.393238Z",
     "start_time": "2025-05-08T14:10:02.638891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy import signal, stats\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_stft(x, fs, clip_fs=-1, normalizing=None, **kwargs):\n",
    "    f, t, Zxx = signal.stft(x, fs, **kwargs)\n",
    "\n",
    "    Zxx = Zxx[:clip_fs]\n",
    "    f = f[:clip_fs]\n",
    "\n",
    "    Zxx = np.abs(Zxx)\n",
    "    clip = 5  #To handle boundary effects\n",
    "    if normalizing == \"zscore\":\n",
    "        Zxx = Zxx[:, clip:-clip]\n",
    "        Zxx = stats.zscore(Zxx, axis=-1)\n",
    "        t = t[clip:-clip]\n",
    "    elif normalizing == \"db\":\n",
    "        Zxx = np.log2(Zxx[:, clip:-clip])\n",
    "        t = t[clip:-clip]\n",
    "\n",
    "    if np.isnan(Zxx).any():\n",
    "        import pdb;\n",
    "        pdb.set_trace()\n",
    "\n",
    "    return f, t, Zxx"
   ],
   "id": "4a412a73fd7d2931",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:10:08.042769Z",
     "start_time": "2025-05-08T14:10:05.860408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "wav = np.load(\"../resources/example_wav_1.npy\")\n",
    "f, t, linear = get_stft(wav, 2048, clip_fs=40, nperseg=400, noverlap=350, normalizing=\"zscore\",\n",
    "                        return_onesided=True)  #TODO hardcode sampling rate\n",
    "inputs = torch.FloatTensor(linear).unsqueeze(0).transpose(1, 2).to('cuda')\n",
    "mask = torch.zeros((inputs.shape[:2])).bool().to('cuda')\n",
    "with torch.no_grad():\n",
    "    out = model.forward(inputs, mask, intermediate_rep=True)\n"
   ],
   "id": "f52129e19499d1a6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "59e795bae6e9ff4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:10:27.006492Z",
     "start_time": "2025-05-08T14:10:26.999629Z"
    }
   },
   "cell_type": "code",
   "source": "out.shape  # Embedding",
   "id": "f8802a44857f0a3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T15:13:34.671827Z",
     "start_time": "2025-05-08T15:13:34.666408Z"
    }
   },
   "cell_type": "code",
   "source": "wav.shape",
   "id": "af8682b5781019ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:43:04.959495Z",
     "start_time": "2025-05-09T15:43:04.938586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dependencies.VATE.contrastive_model import Contrastive_model\n",
    "import torch\n",
    "\n",
    "vate_path = \"../dependencies/VATE/output/VATE/best_model_contrastive.pt\"\n",
    "state = torch.load(vate_path, weights_only=True)"
   ],
   "id": "2179d8a85d0879a6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:43:05.615708Z",
     "start_time": "2025-05-09T15:43:05.455229Z"
    }
   },
   "cell_type": "code",
   "source": "state",
   "id": "950a05568bd5d41f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('logit_scale', tensor(5.0468, device='cuda:0')),\n",
       "             ('embedding_video.0.weight',\n",
       "              tensor([[ 0.6699,  0.9835, -0.3992,  ...,  0.1174,  0.0280, -0.1097],\n",
       "                      [-1.0760,  1.1983,  0.4258,  ...,  1.4139,  0.9089,  0.8064],\n",
       "                      [ 0.0308, -0.1668, -0.0978,  ..., -0.0098, -1.0381,  0.8803],\n",
       "                      ...,\n",
       "                      [-0.7769,  1.1365, -1.5389,  ..., -0.9256, -0.7520,  0.1700],\n",
       "                      [-1.7386, -0.8210,  0.1784,  ..., -0.1769,  0.7469, -0.1340],\n",
       "                      [-0.2822,  0.2668, -0.2194,  ..., -0.1777, -0.5721, -0.4139]],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_video.0.bias',\n",
       "              tensor([-1.0965,  0.0114, -0.8724, -0.3301, -0.4070, -0.2655,  0.3762, -0.3899,\n",
       "                      -0.5425, -1.0984,  0.1562, -0.3874, -0.2192,  0.0014, -0.0918, -0.2529,\n",
       "                      -0.6458, -0.0087,  0.5265, -0.2845, -0.5550, -0.2790,  0.6596, -1.3008,\n",
       "                      -0.1323,  0.1537, -0.4523,  0.2798,  0.0800,  0.0812,  0.4329,  0.0786,\n",
       "                      -0.0962,  0.6037, -0.5515,  0.0603, -0.0758, -0.1196,  0.1463,  0.1019,\n",
       "                      -0.7945, -0.7328, -1.0434, -0.1427, -0.0105, -0.1104, -0.4236, -0.3064,\n",
       "                      -0.3552, -0.2285, -0.1913, -0.1350, -0.7074, -0.4904, -0.8040, -0.3116,\n",
       "                      -1.0075, -0.8245,  0.1341, -0.5495, -0.5977,  0.1454, -0.7039, -0.5516,\n",
       "                      -0.1643,  0.1133, -0.6316,  0.2638, -0.2928, -0.0302, -0.2810,  0.1784,\n",
       "                      -0.8097, -0.4176, -0.1371, -0.1821, -0.1945,  0.0266, -0.3540,  0.3076,\n",
       "                      -0.5049, -0.2169, -0.4422, -0.3375, -0.0256, -0.1719, -0.3806, -0.4571,\n",
       "                      -0.3631,  0.0850, -0.4699, -0.3889,  0.0995, -0.3642, -0.6997, -0.3273,\n",
       "                      -1.0805,  0.4091,  0.1012,  0.0464, -0.2558, -0.0955, -0.2487, -0.2191,\n",
       "                      -0.4135, -0.0479, -1.1164,  0.2952, -0.1419, -0.1884,  0.0769,  0.2662,\n",
       "                      -1.1004, -0.4137, -0.6919, -0.7690,  0.2345,  0.0350, -0.4668, -0.3720,\n",
       "                       0.3332, -0.4585, -0.2176,  0.1883, -0.2084,  0.0182,  0.0124, -0.5334,\n",
       "                      -0.0800, -0.7363, -0.8022, -0.8845, -0.1754, -0.6017, -0.3098, -0.1360,\n",
       "                      -0.3102, -0.1744, -0.3086,  0.1201, -0.1807, -0.1718, -0.8494, -0.1463,\n",
       "                      -0.6710, -0.5782, -0.8075, -0.6314,  0.0849, -0.8710,  0.1675, -0.4802,\n",
       "                      -0.7878, -0.5803, -0.6132, -0.4250, -0.0053,  0.0344, -0.2523, -0.1280,\n",
       "                      -0.5121, -0.0519,  0.1283,  0.6075, -0.2460,  0.3998, -0.4522,  0.0153,\n",
       "                      -0.0665, -0.2287, -0.7049, -0.9425, -0.4537, -0.5956, -0.5053, -0.3395,\n",
       "                      -0.1785, -0.3649, -0.3370, -0.0882, -0.2476, -0.7254, -0.6435, -0.2228,\n",
       "                      -0.8353, -0.4639, -0.0509, -0.7420, -0.1926, -0.5800, -1.1729, -0.4193,\n",
       "                      -0.1992, -0.0857, -0.3830, -0.3601,  0.1577, -0.9287, -0.3263, -0.2653],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_video.2.weight',\n",
       "              tensor([[ 8.9008e-02, -1.1502e-01,  2.5357e-03,  ..., -5.4255e-02,\n",
       "                       -1.0344e-01, -4.5441e-02],\n",
       "                      [-6.5337e-01,  6.6046e-01, -9.5081e-01,  ..., -3.3606e+00,\n",
       "                        2.1162e-01, -1.1895e+00],\n",
       "                      [-1.0857e-01,  6.7230e-02, -4.8168e-02,  ..., -1.0814e-01,\n",
       "                       -4.8487e-02, -1.1902e-02],\n",
       "                      ...,\n",
       "                      [ 4.6480e-01, -1.5620e+00,  9.7149e-02,  ..., -1.3400e+00,\n",
       "                        4.3615e-01,  6.7329e-01],\n",
       "                      [-1.0451e+00, -3.7787e-01, -3.7472e-01,  ...,  6.6630e-01,\n",
       "                       -1.1195e+00,  3.2879e-02],\n",
       "                      [ 2.5869e-01,  6.6929e-01,  4.9625e-02,  ...,  1.6262e+00,\n",
       "                       -3.7871e-01, -5.8692e-03]], device='cuda:0')),\n",
       "             ('embedding_video.2.bias',\n",
       "              tensor([-2.2034e-02, -1.1163e+00, -1.2450e-01, -4.0533e-03, -8.9944e-02,\n",
       "                      -5.9925e-01, -4.5872e-01, -1.3143e+00, -5.1952e-01,  8.1796e-01,\n",
       "                      -2.2184e+00,  2.5010e-01, -9.3662e-02, -2.9436e-02, -1.1559e+00,\n",
       "                      -3.7856e-01,  6.9415e-01, -1.4777e+00,  1.9195e-01, -6.4513e-01,\n",
       "                       7.4639e-01,  5.3535e-01,  1.6681e+00, -8.5423e-01,  1.4644e-02,\n",
       "                      -7.1833e-02, -4.9936e-01, -7.5485e-01,  1.5087e+00, -3.7406e-01,\n",
       "                       3.7315e-01,  2.8547e-02, -6.2839e-02, -1.6029e+00, -7.8521e-01,\n",
       "                      -1.6070e-01, -2.3448e-02, -1.6383e+00, -6.2176e-02, -7.3973e-01,\n",
       "                      -1.4045e+00, -5.6389e-01, -1.0620e-01, -7.2576e-02, -5.5908e-01,\n",
       "                       6.7776e-01,  1.5680e-01, -1.5881e+00, -6.4711e-02, -1.5847e+00,\n",
       "                       1.5464e-01, -1.1115e+00, -1.8664e-02,  1.1239e+00, -1.5576e+00,\n",
       "                      -1.0260e-01, -1.2924e+00, -1.2361e-01, -1.3837e-01, -1.0913e+00,\n",
       "                      -7.6756e-01,  1.2529e-01, -1.2674e+00, -6.6244e-02,  4.0999e-01,\n",
       "                      -1.2952e-01, -1.8469e+00,  9.5210e-01,  1.4443e+00, -1.5208e-01,\n",
       "                       2.7180e-01,  1.2966e+00, -2.4013e+00, -5.4553e-01, -5.6089e-01,\n",
       "                      -1.5828e-01, -1.1057e+00, -9.3855e-02, -9.1065e-02,  6.6733e-01,\n",
       "                      -1.2282e-01, -6.8246e-01,  4.6831e-01, -5.2381e-02, -4.2171e-01,\n",
       "                      -8.5035e-02,  5.2785e-01, -3.1535e-02, -3.1235e-01,  5.0012e-01,\n",
       "                      -8.5563e-02, -3.3475e-01, -6.0222e-01, -6.2302e-02, -3.2596e+00,\n",
       "                      -1.9812e-01, -2.4239e+00, -3.5968e-02, -8.2485e-01, -5.8397e-01,\n",
       "                      -1.1094e+00, -1.5964e+00, -9.7850e-01, -2.6076e+00, -1.8740e+00,\n",
       "                       3.2458e-01, -1.4076e+00, -7.6981e-01, -8.5714e-01,  1.6809e-01,\n",
       "                      -5.8487e-02, -3.0618e-02, -1.8399e+00,  1.0404e+00, -2.9652e-01,\n",
       "                      -1.5665e+00, -8.8555e-02, -8.9000e-01,  6.9704e-03, -2.7239e-01,\n",
       "                       1.4842e-01, -3.7547e-01, -2.4145e+00, -2.2247e-01, -1.2928e-01,\n",
       "                       3.8815e-01, -7.2053e-02, -6.2221e-01, -2.1735e-01, -8.9153e-02,\n",
       "                       5.1236e-01,  1.7568e+00, -1.0018e-01, -8.1552e-02, -4.2730e-02,\n",
       "                      -2.5047e-02, -7.1544e-01, -5.3724e-01,  1.0388e+00, -3.5927e-02,\n",
       "                      -1.3933e+00,  2.2522e-02,  3.0916e-01, -2.2602e+00,  5.9158e-01,\n",
       "                      -1.2940e+00, -6.5367e-02, -6.6263e-02,  2.2880e-01, -8.0785e-01,\n",
       "                      -7.0820e-01,  7.1575e-01, -9.5518e-01,  7.6773e-01, -1.2169e+00,\n",
       "                       1.9911e-02,  4.6997e-01, -1.0162e-01, -6.6820e-02, -5.9262e-02,\n",
       "                      -5.7582e-01,  9.6734e-01, -3.2691e-01,  6.8842e-01, -1.8485e+00,\n",
       "                      -2.5838e-01, -6.2346e-01,  7.5631e-02,  4.3616e-01, -1.4734e-02,\n",
       "                       7.7269e-01,  7.5524e-01, -7.7546e-01,  3.4551e-01,  8.3331e-04,\n",
       "                       1.1591e+00, -1.7239e-01,  2.1559e+00, -2.9960e-01, -1.1721e+00,\n",
       "                      -4.3529e-01,  7.9259e-02, -1.2655e-02, -5.2362e-01, -4.8055e-01,\n",
       "                      -1.6523e+00, -8.5774e-01, -6.7807e-02, -1.4544e+00, -4.9497e-02,\n",
       "                      -1.3321e-01, -3.6723e-02,  5.6622e-01, -1.1915e+00, -4.0414e-01,\n",
       "                       1.8189e-02, -1.5981e+00, -9.5177e-01, -1.3619e+00, -2.8708e+00],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_video.4.weight',\n",
       "              tensor([[-0.0043, -0.0295, -0.0389,  ..., -0.4040, -0.9092,  0.0027],\n",
       "                      [ 0.1334,  1.1058,  0.0213,  ...,  0.6859, -0.4492, -0.0111],\n",
       "                      [ 0.0548, -0.3849, -0.0341,  ...,  0.0811,  0.4637, -0.4013],\n",
       "                      ...,\n",
       "                      [-0.0058, -1.3601, -0.0531,  ..., -0.2342, -0.5749,  1.5544],\n",
       "                      [-0.0100,  0.2061,  0.0142,  ..., -0.2812, -0.2199, -1.0445],\n",
       "                      [-0.1007,  1.0200,  0.0413,  ..., -0.5429, -0.0269,  0.3236]],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_video.4.bias',\n",
       "              tensor([-5.3963, -0.7435, -4.8899,  4.9202,  1.4863,  2.4561, -3.5742, -3.6284,\n",
       "                      -3.0102,  7.6475, -0.5460,  0.1452, -5.1481, -0.8406, -8.8368, -0.3384,\n",
       "                       2.0683,  4.5691,  1.6622,  3.9825, -0.6653,  2.1810,  6.0266, -2.0062,\n",
       "                      -0.0198,  0.5344,  0.2794,  3.5711,  3.7113, -1.1352,  5.8604,  2.1073,\n",
       "                      -4.6542,  2.7004, -7.5687, -0.5755, -4.5021, -0.3460,  2.5343,  1.9915,\n",
       "                       5.0244,  0.9956, -3.4712, -0.5693, -1.1153,  2.2726,  5.2016, -2.3013,\n",
       "                       0.5233,  0.0909, -3.6347,  0.0351,  4.2555, -4.1174, -2.5681, -2.5616,\n",
       "                      -1.2280, -0.6422, -0.8807,  1.3540, -2.7646, -3.3330,  3.1454, -2.4702,\n",
       "                       5.0591, -1.7601, -1.7478, -3.7409,  1.8927,  0.8173, -3.4658, -2.5510,\n",
       "                      -1.3517,  2.6663, -2.5171,  2.4034, -1.0995, -1.1399,  1.3692, -1.0111,\n",
       "                       1.7847,  1.0527,  4.0788,  3.0145,  3.3503, -0.7920, -8.3049, -2.3962,\n",
       "                      -0.7929, -0.2602, -2.9470, -3.2490, -1.0161, -2.3429,  1.8290, -1.6714,\n",
       "                      -1.5977,  1.1870, -1.2978, -9.4587], device='cuda:0')),\n",
       "             ('embedding_audio.0.weight',\n",
       "              tensor([[-0.2112, -0.4206, -0.0478,  ..., -0.4874,  0.5244, -0.2677],\n",
       "                      [-0.0781,  0.0678,  0.0592,  ...,  0.0332,  0.0693, -0.0408],\n",
       "                      [-1.4755,  1.8686, -0.4530,  ...,  0.5831,  0.2050,  0.0553],\n",
       "                      ...,\n",
       "                      [ 0.6235,  0.4948,  1.0440,  ..., -0.8932,  0.0886,  0.3650],\n",
       "                      [-0.0884, -0.0355,  0.0510,  ...,  0.0379,  0.0423, -0.0278],\n",
       "                      [-1.3132,  0.2721,  1.8653,  ..., -0.2343, -0.0963, -0.4099]],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_audio.0.bias',\n",
       "              tensor([-0.3520, -0.0425, -0.4173, -0.0893,  0.0069,  0.0753,  0.0015, -0.1779,\n",
       "                      -0.0249,  0.0219, -0.1586,  0.0882,  0.0910,  0.0301,  0.1439,  0.1279,\n",
       "                      -0.0505, -0.0416, -0.1405, -0.0215, -0.0078, -0.0548, -0.0901, -0.0757,\n",
       "                      -0.0362,  0.2246,  0.0567, -0.2579, -0.0771, -0.0463, -0.1685, -0.2223,\n",
       "                      -0.0775, -0.1226,  0.1509,  0.2425, -0.0757,  0.0611,  0.1833, -0.0497,\n",
       "                      -0.4532,  0.0837, -0.0653, -0.0392, -0.0264,  0.3034, -0.4201, -0.1147,\n",
       "                      -0.1816, -0.0830,  0.0096, -0.0434,  0.2503, -0.1874, -0.1494, -0.1277,\n",
       "                      -0.1669, -0.0271, -0.0559, -0.0435, -0.0903, -0.0478,  0.0980, -0.0546,\n",
       "                      -0.0520, -0.2301, -0.0878, -0.2449,  0.2126, -0.0845, -0.0397, -0.0851,\n",
       "                       0.1120,  0.1899, -0.1050,  0.0363,  0.0069, -0.0913, -0.4749, -0.0148,\n",
       "                      -0.0904, -0.1221, -0.0306,  0.0766,  0.0172,  0.0089, -0.2176, -0.0482,\n",
       "                      -0.0803,  0.2720,  0.0527, -0.3392, -0.0753,  0.1137, -0.0679,  0.2639,\n",
       "                      -0.0209,  0.0364,  0.0091, -0.3061, -0.3382, -0.0082, -0.2534,  0.0486,\n",
       "                      -0.2223,  0.0677, -0.1953, -0.0912,  0.1166,  0.0492,  0.0921, -0.1635,\n",
       "                      -0.1305, -0.0786, -0.0378, -0.2995, -0.0997, -0.3369, -0.0325, -0.0817,\n",
       "                      -0.3893,  0.0784, -0.1051,  0.0452, -0.0741, -0.2372, -0.0937, -0.0398,\n",
       "                      -0.3983,  0.2586, -0.0260,  0.2448, -0.1244,  0.0500,  0.1355,  0.1344,\n",
       "                      -0.2669, -0.0477, -0.1745, -0.0311,  0.2307, -0.1324,  0.0703, -0.1313,\n",
       "                      -0.2123, -0.1881, -0.0265, -0.0180, -0.1320,  0.2061,  0.0735,  0.0175,\n",
       "                       0.0105, -0.4940, -0.2866,  0.0872,  0.0096, -0.0524, -0.0146,  0.1316,\n",
       "                      -0.1212,  0.0393, -0.0630, -0.0957, -0.1460,  0.1664, -0.0739,  0.0469,\n",
       "                      -0.0795, -0.0193, -0.1155, -0.0632, -0.1188, -0.2205,  0.0908, -0.2273,\n",
       "                      -0.0185,  0.0525, -0.2938,  0.0252,  0.0542,  0.2676,  0.0660, -0.0697,\n",
       "                       0.1757, -0.0146, -0.0617, -0.0783, -0.0807, -0.0716, -0.1070, -0.0732,\n",
       "                       0.3714, -0.0020, -0.0375, -0.0574, -0.0818,  0.0339, -0.0348,  0.0014],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_audio.2.weight',\n",
       "              tensor([[-3.6193e+00,  9.1758e-02, -3.5945e-01,  ...,  2.1083e-01,\n",
       "                        9.3351e-02,  8.2021e-01],\n",
       "                      [-1.4757e-03, -1.2485e-01,  1.5055e-02,  ..., -5.1804e-02,\n",
       "                        1.1071e-01, -1.3566e-01],\n",
       "                      [ 4.2823e-02, -1.0079e-02,  3.7457e-02,  ..., -1.2129e-01,\n",
       "                        9.3455e-02, -4.1907e-02],\n",
       "                      ...,\n",
       "                      [-5.3490e-02, -6.5723e-02, -6.8236e-02,  ..., -7.4336e-02,\n",
       "                       -1.4488e-02, -3.9582e-02],\n",
       "                      [-1.9942e+00,  1.5209e-02, -1.6885e-01,  ..., -1.7657e-01,\n",
       "                       -3.9623e-03,  2.9963e-01],\n",
       "                      [-2.4477e-02,  3.2214e-03,  3.2624e-03,  ..., -9.5239e-02,\n",
       "                        1.2025e-02, -1.5179e-01]], device='cuda:0')),\n",
       "             ('embedding_audio.2.bias',\n",
       "              tensor([ 1.9852e-01, -5.3060e-02,  2.9028e-03,  3.5596e-01,  1.5788e-01,\n",
       "                      -3.4504e-01,  7.6611e-02, -1.0747e+00, -1.5203e-01, -1.9421e-02,\n",
       "                      -1.0943e+00,  7.5577e-02,  4.1532e-01, -5.0162e-01, -1.4438e-01,\n",
       "                       2.1865e-01, -1.1732e-01, -1.4139e-01, -1.2479e+00, -5.3715e-01,\n",
       "                      -2.4290e-02,  3.8965e-04, -1.0811e-01,  1.7288e-01,  4.0652e-01,\n",
       "                      -4.0043e-01, -1.0303e+00,  1.5061e-01, -8.4028e-02,  1.8980e-01,\n",
       "                      -8.8723e-01, -3.9384e-01, -7.2738e-03, -1.2040e+00,  1.2522e-01,\n",
       "                      -7.9031e-01, -2.1745e-01,  9.6291e-02, -1.5185e-01,  2.4864e-01,\n",
       "                      -6.4421e-02, -3.1059e-01, -9.8274e-02,  4.5811e-01, -1.2554e-02,\n",
       "                      -2.6651e-03, -6.0441e-02,  5.9991e-01, -3.1752e-01, -2.1177e-01,\n",
       "                      -8.2313e-01,  1.1255e-01,  3.5478e-01, -2.2847e-02, -1.2241e-01,\n",
       "                       1.9948e-01,  2.2502e-01, -1.2386e-01, -5.6907e-01,  1.4839e-01,\n",
       "                       2.6041e-01, -1.1010e-01, -6.0151e-01, -4.0406e-01,  5.3231e-01,\n",
       "                      -2.7258e-01, -1.2019e-01,  3.6349e-02, -1.3053e-02, -7.7547e-02,\n",
       "                       5.9667e-01, -2.2689e-01,  4.2257e-01,  2.0360e-01, -5.1750e-01,\n",
       "                      -1.7714e+00,  3.8359e-01,  1.7867e-01, -2.6387e-01, -1.1665e-02,\n",
       "                      -5.9326e-02, -3.0828e-01, -5.8375e-02, -1.2907e-01,  6.8989e-02,\n",
       "                       8.2070e-01, -3.3523e-01, -3.6235e-01, -6.4382e-01, -2.3149e-01,\n",
       "                      -1.0996e-01, -1.1346e+00,  6.1904e-01, -3.1889e-01, -3.5117e-02,\n",
       "                      -3.4397e-01, -5.4874e-02, -3.0694e-02,  3.6397e-01, -2.7262e-01,\n",
       "                      -2.2371e-01, -1.4001e-02,  4.7573e-01, -6.2000e-02, -8.0760e-02,\n",
       "                      -1.9984e-01, -4.8576e-01,  7.6138e-01,  2.8542e-01,  1.8802e-02,\n",
       "                      -7.3979e-01, -1.3143e-01,  2.9496e-01, -6.9166e-03, -3.9793e-01,\n",
       "                       2.3210e-03, -2.3513e-01, -6.4419e-01,  2.8709e-03,  3.2762e-01,\n",
       "                      -1.3094e-01,  5.6204e-02, -9.0972e-01,  8.4647e-02, -6.4155e-02,\n",
       "                       7.1773e-01, -3.1731e-02, -1.4785e-02, -6.7747e-02,  4.0001e-01,\n",
       "                       6.4372e-02,  1.0952e-01, -1.3606e-01,  3.6560e-01, -4.7051e-01,\n",
       "                       1.1138e+00, -4.3914e-01,  4.9669e-01, -1.8212e-01,  1.4991e-01,\n",
       "                       7.4834e-02, -2.9467e-01, -1.3686e-01, -3.3082e-01, -4.2710e-03,\n",
       "                      -2.6941e-01,  4.1780e-01, -9.6484e-02,  1.1991e-02,  4.7154e-02,\n",
       "                       6.3594e-01, -1.1020e-01, -2.2689e-01, -1.2362e+00, -1.1565e-01,\n",
       "                      -1.0066e-01,  5.8370e-01, -5.0750e-02, -8.3017e-02, -1.5266e-01,\n",
       "                      -4.7106e-02, -6.3967e-01,  1.2755e-01, -1.0794e-01, -1.2426e-01,\n",
       "                      -8.5185e-02, -1.1246e-01,  5.7813e-01,  4.5874e-01,  7.2661e-01,\n",
       "                      -2.8211e-01, -9.1989e-02, -1.0304e-01, -2.5939e-01, -1.0824e-01,\n",
       "                       1.9478e-01, -4.4986e-01, -1.3320e-01, -5.3065e-01,  5.8961e-02,\n",
       "                      -1.1221e-01,  2.8865e-01,  1.1460e-01,  7.0304e-02,  7.8606e-01,\n",
       "                      -5.8177e-03, -4.3373e-01, -3.6757e-02,  4.8808e-02,  7.3377e-01,\n",
       "                       5.9014e-01, -2.3284e-01, -8.1725e-02,  5.5590e-01, -6.0619e-02,\n",
       "                       7.0724e-01, -3.3247e-01, -9.4967e-02,  2.2942e-01, -1.0184e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_audio.4.weight',\n",
       "              tensor([[ 3.7144e-01,  9.1436e-02,  1.2733e-02,  ...,  9.3991e-02,\n",
       "                        5.9953e-01,  6.2544e-02],\n",
       "                      [ 9.2020e-01, -2.1338e-01, -1.3637e-01,  ...,  7.8993e-03,\n",
       "                        4.6289e-01,  1.4646e-02],\n",
       "                      [-1.6995e+00,  4.8098e-02,  8.0667e-03,  ..., -8.5245e-02,\n",
       "                        1.5734e+00, -1.0028e-02],\n",
       "                      ...,\n",
       "                      [-6.5863e-01,  3.8659e-02, -5.2711e-04,  ..., -6.3922e-02,\n",
       "                        1.3121e+00, -6.3318e-02],\n",
       "                      [-7.8572e-02, -1.0595e-01,  9.2438e-02,  ...,  4.7456e-02,\n",
       "                       -1.2992e-01, -8.8289e-02],\n",
       "                      [-1.8925e-01,  4.4269e-02, -2.2687e-02,  ..., -1.0651e-01,\n",
       "                        3.0814e-01,  3.3115e-02]], device='cuda:0')),\n",
       "             ('embedding_audio.4.bias',\n",
       "              tensor([ 0.7136,  0.0744, -0.7274, -0.2213,  0.9787, -1.7803,  0.4695,  0.6494,\n",
       "                      -0.7965, -0.2724,  1.5229,  0.8824,  0.1828, -0.6768, -0.0490, -0.0068,\n",
       "                      -0.8455,  0.4536,  0.0122,  0.9186, -0.0292, -0.4702,  0.1685, -0.3566,\n",
       "                      -1.0502,  0.3876, -0.5316, -0.7419,  0.9993,  0.7797, -0.0751,  0.5943,\n",
       "                      -0.0541, -0.8637, -1.5017,  0.1512,  0.1953, -0.3323,  0.6193,  0.4297,\n",
       "                       0.4082,  0.8644, -0.1725,  0.5970, -1.2778,  1.1860,  0.8477,  0.3236,\n",
       "                      -0.1645,  0.6984,  0.3759,  0.9382, -0.3001, -0.5677, -1.2638, -1.3289,\n",
       "                      -0.4231,  0.2177,  0.0621, -0.4182, -0.2818, -0.5629,  0.3555,  0.2086,\n",
       "                       0.5609,  0.5420,  0.1412,  0.9784, -0.1737, -0.5684, -0.1355, -1.4131,\n",
       "                       0.3380,  0.7761, -0.5981,  0.3057,  0.0638, -0.1255, -0.6155,  0.8325,\n",
       "                       0.4678, -0.0761, -0.2971,  1.1441, -0.4566, -0.4706,  0.8535, -2.1642,\n",
       "                       0.3683, -0.7350, -0.6560, -0.7201,  0.1306, -0.5036,  0.0296, -0.3898,\n",
       "                      -1.2347, -0.0792,  0.2553, -0.3613], device='cuda:0')),\n",
       "             ('embedding_text.0.weight',\n",
       "              tensor([[-0.3574, -0.4365, -0.0048,  ...,  0.4239,  0.7179,  0.2889],\n",
       "                      [ 0.1358, -0.0427, -0.2076,  ...,  2.2477,  0.0247, -0.0253],\n",
       "                      [ 0.0653,  0.0246, -0.0746,  ...,  0.0825,  0.0838, -0.0555],\n",
       "                      ...,\n",
       "                      [ 0.0760,  0.0739, -0.0530,  ..., -0.0414,  0.0544, -0.0438],\n",
       "                      [ 0.0368,  0.0792, -0.0702,  ..., -0.0876,  0.0719, -0.0653],\n",
       "                      [ 0.0758,  0.0394,  0.0449,  ...,  0.0355,  0.0968, -0.1036]],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_text.0.bias',\n",
       "              tensor([-0.4358,  0.0236, -0.0385, -0.0293, -0.0512, -0.0336, -0.0985, -0.0148,\n",
       "                      -0.0468, -0.0949, -0.0982, -0.0515,  0.0736, -0.0425, -0.0297,  0.0702,\n",
       "                      -0.0726, -0.0127, -0.0420, -0.0015, -0.0115, -0.0242, -0.0447, -0.1741,\n",
       "                      -0.0608, -0.0409, -0.0947, -0.0358,  0.0781, -0.1751, -0.0399, -0.0288,\n",
       "                       0.1663,  0.0641, -0.0241,  0.0269, -0.0512,  0.0103, -0.0787, -0.0051,\n",
       "                      -0.1114, -0.0713, -0.0431, -0.0420, -0.0551,  0.1743, -0.0901, -0.0104,\n",
       "                      -0.0351, -0.0763, -0.0967, -0.0301, -0.0499, -0.0507,  0.0732, -0.0764,\n",
       "                      -0.0591, -0.0903, -0.0650, -0.1079, -0.0254, -0.0593,  0.0993,  0.0590,\n",
       "                      -0.0882,  0.0078, -0.0651,  0.0211, -0.0869, -0.0303,  0.0617, -0.0864,\n",
       "                      -0.0797, -0.0355, -0.0737, -0.0943, -0.0355, -0.0621,  0.0033,  0.0135,\n",
       "                      -0.1028,  0.0516,  0.0892, -0.0114, -0.0575,  0.0331,  0.0132, -0.0643,\n",
       "                      -0.0958, -0.0703, -0.0074,  0.0166, -0.0322, -0.0845,  0.0579,  0.0883,\n",
       "                      -0.0872, -0.0662, -0.0288, -0.0255, -0.0800, -0.0142,  0.0129, -0.0927,\n",
       "                      -0.0440, -0.0117, -0.0085, -0.0486, -0.0572, -0.0945, -0.0789, -0.0560,\n",
       "                      -0.1080, -0.0752, -0.0276, -0.0329, -0.1126, -0.2078, -0.0626, -0.2775,\n",
       "                       0.0158,  0.0080, -0.0404, -0.0449, -0.1157, -0.0486, -0.1218, -0.1760,\n",
       "                      -0.0945, -0.0364, -0.0898, -0.0893, -0.1048, -0.1166, -0.1301, -0.0915,\n",
       "                      -0.0468, -0.1867,  0.1707, -0.1084, -0.0354, -0.1343, -0.0746, -0.1625,\n",
       "                      -0.0392, -0.0632, -0.0346, -0.0709, -0.0303, -0.0272, -0.0611, -0.2494,\n",
       "                      -0.0719,  0.0063, -0.0151,  0.0096, -0.0700, -0.3501, -0.0297, -0.0964,\n",
       "                      -0.1185, -0.0345, -0.0641, -0.0788,  0.0362,  0.0095,  0.0209, -0.1649,\n",
       "                      -0.0271, -0.0326, -0.0280, -0.1505, -0.1483,  0.0280,  0.0242, -0.0604,\n",
       "                      -0.0594, -0.1181, -0.0133, -0.1318, -0.0597, -0.0934, -0.0201, -0.2764,\n",
       "                      -0.2308, -0.1544,  0.0026, -0.0542, -0.0965, -0.0680, -0.0551, -0.0419,\n",
       "                       0.0093, -0.0368, -0.0349, -0.0618, -0.0917, -0.0814, -0.0427, -0.0399],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_text.2.weight',\n",
       "              tensor([[-2.7618e+00, -2.6004e-01, -3.8132e-03,  ...,  1.2474e-02,\n",
       "                        4.3388e-02,  8.6433e-02],\n",
       "                      [-2.8405e-02, -1.2797e-01, -3.7885e-02,  ...,  2.0453e-02,\n",
       "                       -5.4209e-02, -6.1968e-02],\n",
       "                      [-1.7394e-02, -7.3183e-02, -5.3710e-02,  ..., -6.0632e-02,\n",
       "                        4.6216e-02, -2.2614e-02],\n",
       "                      ...,\n",
       "                      [-1.3772e-01, -4.1484e-03,  5.7694e-04,  ...,  9.5997e-02,\n",
       "                       -3.2916e-03,  5.2970e-02],\n",
       "                      [ 2.1903e+00, -2.8401e+00, -1.3334e-02,  ..., -4.1404e-02,\n",
       "                        6.2692e-02,  6.3872e-03],\n",
       "                      [-2.6956e-02, -8.4214e-02,  7.9102e-02,  ...,  3.2093e-03,\n",
       "                        4.5186e-02,  8.3315e-02]], device='cuda:0')),\n",
       "             ('embedding_text.2.bias',\n",
       "              tensor([-0.3896, -0.1005,  0.0416, -0.1136, -0.0359, -0.0795,  1.1940,  0.3488,\n",
       "                      -0.0751,  0.1122, -0.0910, -0.0109, -0.0802, -0.1507, -0.0993, -0.0907,\n",
       "                      -0.1189, -0.0768, -0.8373, -0.0326, -0.2401,  0.2879, -0.0777,  0.0253,\n",
       "                      -0.0628,  0.4476, -0.0401,  0.3608,  0.0416, -0.0659, -0.1115, -0.0651,\n",
       "                      -0.0275,  0.0928, -0.1296, -0.0437, -0.1218,  0.0525,  0.9540, -0.1857,\n",
       "                      -0.1215,  0.7897, -0.2240, -0.3972,  0.0603,  0.2031, -0.0504,  0.8448,\n",
       "                      -0.9011, -0.0687, -0.1267, -0.0067,  0.1699, -0.0460, -0.1101, -0.8087,\n",
       "                       0.4236,  0.4708, -0.2436, -0.0733, -0.0164, -0.2449, -0.2659,  0.1146,\n",
       "                      -0.0785, -0.1616,  0.7962, -0.0193, -1.2695, -0.7677, -0.0153,  0.5843,\n",
       "                      -0.0963, -0.0736, -0.0826, -0.0089, -0.6772,  0.1968, -0.1086,  0.0311,\n",
       "                      -0.0564,  0.6685,  0.0099, -0.0283, -0.0623, -0.0517, -0.0640, -0.2973,\n",
       "                       0.2657,  0.0261,  0.4390, -0.0290,  0.3252, -0.1988, -0.0178, -0.6975,\n",
       "                      -0.1803, -0.0764, -1.1286, -0.7865,  0.2438, -0.0217, -0.1696, -0.1623,\n",
       "                      -0.0623, -0.3420,  0.0347, -0.0831, -0.3749, -0.0766, -0.0857, -0.0125,\n",
       "                       0.4895, -0.5207, -0.0470, -0.0036,  0.0340, -0.7026, -0.1061, -0.0399,\n",
       "                      -0.0087,  0.1704, -1.1321, -0.5754, -0.3957, -0.1923, -0.0567,  0.3675,\n",
       "                      -0.2843,  0.1366, -0.0617,  0.0729,  0.4456, -0.3077, -0.0099, -0.2414,\n",
       "                       0.3103, -0.0441, -0.2307, -0.0778,  0.5658,  0.2989, -0.0679, -0.2961,\n",
       "                      -0.0511, -0.0564, -0.0184, -1.3411, -0.1170, -0.0863, -0.2552, -0.0338,\n",
       "                      -0.0933, -0.1276, -0.0836, -0.4258,  0.4694, -0.4079, -0.4868,  1.0536,\n",
       "                       1.1264, -0.0554, -0.1578,  0.2797,  0.7259, -0.1140, -0.7319, -0.0361,\n",
       "                       0.2246, -0.0489, -0.0460, -0.0777, -0.2645, -0.0607, -0.1489, -0.2904,\n",
       "                      -0.0311,  0.7286, -0.0945, -0.0938, -0.0168,  0.6615, -0.3774, -0.1290,\n",
       "                       0.4390, -0.8314,  0.0872, -0.3253, -0.1437,  0.9118, -0.1443, -0.0541,\n",
       "                       0.4848, -0.0923, -0.0126, -0.0325, -0.1168,  0.0368, -0.7782,  0.0419],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_text.4.weight',\n",
       "              tensor([[ 1.4313,  0.0611, -0.0275,  ..., -0.1156, -0.0243, -0.1201],\n",
       "                      [-0.8289, -0.0820, -0.0586,  ...,  0.0645,  1.3568, -0.2669],\n",
       "                      [ 0.2312, -0.0819, -0.0983,  ..., -0.0258,  0.8432, -0.1820],\n",
       "                      ...,\n",
       "                      [-0.0348,  0.0999,  0.0285,  ..., -0.0389, -0.3510,  0.0445],\n",
       "                      [ 0.3882, -0.0900,  0.1078,  ...,  0.0028,  0.4222,  0.1564],\n",
       "                      [-0.2000, -0.0491, -0.0770,  ...,  0.2340, -0.5710,  0.1181]],\n",
       "                     device='cuda:0')),\n",
       "             ('embedding_text.4.bias',\n",
       "              tensor([ 2.0035,  0.3721, -1.9729,  0.1019, -1.3829, -0.1311, -2.7289, -2.1712,\n",
       "                      -0.6424,  0.5767, -0.6064,  0.6124,  1.4088,  1.0101, -0.0764,  1.1856,\n",
       "                      -1.1152, -4.5885, -2.1347, -0.6081, -1.5301, -2.3146, -0.2418,  0.8859,\n",
       "                       2.7195, -0.1106,  0.5663,  1.0644, -2.4526, -1.9703, -2.4050, -0.7506,\n",
       "                       1.7066, -1.6757,  0.6169,  0.3941,  2.8590, -0.6543, -0.1023, -0.0454,\n",
       "                      -4.2805,  0.0247, -0.9115, -2.1829, -0.8270, -0.3611,  0.4621,  1.5577,\n",
       "                       0.3169,  0.3736,  1.2613,  0.0888, -0.4385, -0.9599,  0.1989,  0.3952,\n",
       "                       3.5925,  4.2851,  0.2692, -3.1264, -0.2739, -0.2432, -1.1849, -0.0225,\n",
       "                      -1.7597,  2.6072, -0.3734, -0.1911, -0.6714,  4.0105,  1.1783, -0.8980,\n",
       "                      -1.2570,  0.9881, -0.2637, -1.4596,  0.7849,  2.5425,  1.4363,  3.2346,\n",
       "                       0.2594, -0.9383, -1.6305, -0.1072,  0.6174, -2.4077,  0.5230,  2.0999,\n",
       "                      -2.4820,  0.7577,  0.7731,  0.7578,  0.5789, -3.5605, -0.2475, -0.7240,\n",
       "                       0.3948, -0.4737,  0.6922,  2.2674], device='cuda:0'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:43:06.585605Z",
     "start_time": "2025-05-09T15:43:06.579588Z"
    }
   },
   "cell_type": "code",
   "source": "state['embedding_text.4.weight'].shape",
   "id": "e9605e5704d5efc1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 200])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:43:12.487322Z",
     "start_time": "2025-05-09T15:43:12.474192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vate_model = Contrastive_model(200, 100)\n",
    "vate_model.load_state_dict(state)"
   ],
   "id": "62e78dbede234445",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:43:20.515410Z",
     "start_time": "2025-05-09T15:43:20.509908Z"
    }
   },
   "cell_type": "code",
   "source": "vate_model.eval()",
   "id": "694b22070725a2dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contrastive_model(\n",
       "  (embedding_video): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "  )\n",
       "  (embedding_audio): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "  )\n",
       "  (embedding_text): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T15:45:03.202654Z",
     "start_time": "2025-05-09T15:45:03.101685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video = \"\"\n",
    "vate_model.forward(video, None,None)"
   ],
   "id": "58911ff2315fcc10",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m video = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mvate_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\dependencies\\VATE\\contrastive_model.py:35\u001B[39m, in \u001B[36mContrastive_model.forward\u001B[39m\u001B[34m(self, x_video, x_audio, x_text)\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_video, x_audio, x_text = \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m     x_video = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membedding_video\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_video\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     36\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m x_audio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     37\u001B[39m         x_audio = \u001B[38;5;28mself\u001B[39m.embedding_audio(x_audio)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: linear(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:26:28.953271Z",
     "start_time": "2025-05-13T14:26:28.950199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0,os.path.abspath(\"../dependencies/VATE\"))"
   ],
   "id": "5ccb266410cf03a9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:26:29.876610Z",
     "start_time": "2025-05-13T14:26:29.745925Z"
    }
   },
   "cell_type": "code",
   "source": "from VATE.text import Text # COOOL!",
   "id": "e1503096aacca85e",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mVATE\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Text\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\progetto-tesi-magistrale\\dependencies\\VATE\\VATE\\text.py:3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdataclasses\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dataclass\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlibrosa\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'librosa'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "130a2c653880cda0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
