{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-02T17:34:41.722037Z",
     "start_time": "2025-09-02T17:34:37.060244Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from models.single_media_EEGAVI.single_media_EEGAVI import SingleMediaEEGAVI\n",
    "\n",
    "model = SingleMediaEEGAVI()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VivitModel were not initialized from the model checkpoint at google/vivit-b-16x2-kinetics400 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/jacopo/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:34:42.495332Z",
     "start_time": "2025-09-02T17:34:41.725094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.single_media_EEGAVI.dataset import kd_train_dataset\n",
    "\n",
    "ds = kd_train_dataset(\"../../resources/AMIGOS/processed/spec.csv\")"
   ],
   "id": "a1269cc602d9f485",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:34:43.310833Z",
     "start_time": "2025-09-02T17:34:42.499512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loader = DataLoader(ds, batch_size=2)\n",
    "x = next(iter(loader))"
   ],
   "id": "4d4fec0e49f5eca8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../../resources/AMIGOS/processed/P01_31_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 19885 =      0.000 ...   155.352 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to `SeamlessM4TFeatureExtractor()`. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../../resources/AMIGOS/processed/P01_31_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 19885 =      0.000 ...   155.352 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to `SeamlessM4TFeatureExtractor()`. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:34:43.652Z",
     "start_time": "2025-09-02T17:34:43.639452Z"
    }
   },
   "cell_type": "code",
   "source": "x[0][\"EEGAVI\"][\"vid\"].pixel_values.shape",
   "id": "113268cf579318dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:37:49.450947Z",
     "start_time": "2025-09-02T17:34:43.686223Z"
    }
   },
   "cell_type": "code",
   "source": "res = model(x[0][\"EEGAVI\"])",
   "id": "61b3f400b70fd776",
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"(b T) f c w h -> b T f c w h\".\n Input tensor shape: torch.Size([2, 3137, 768]). Additional info: {'b': 2}.\n Wrong shape: expected 5 dims. Received 3-dim tensor.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mEinopsError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/einops/einops.py:531\u001B[39m, in \u001B[36mreduce\u001B[39m\u001B[34m(tensor, pattern, reduction, **axes_lengths)\u001B[39m\n\u001B[32m    530\u001B[39m shape = backend.shape(tensor)\n\u001B[32m--> \u001B[39m\u001B[32m531\u001B[39m recipe = \u001B[43m_prepare_transformation_recipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxes_names\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43maxes_lengths\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndim\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    532\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _apply_recipe(\n\u001B[32m    533\u001B[39m     backend, recipe, cast(Tensor, tensor), reduction_type=reduction, axes_lengths=hashable_axes_lengths\n\u001B[32m    534\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/einops/einops.py:366\u001B[39m, in \u001B[36m_prepare_transformation_recipe\u001B[39m\u001B[34m(pattern, operation, axes_names, ndim)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ndim != \u001B[38;5;28mlen\u001B[39m(left.composition):\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m EinopsError(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mWrong shape: expected \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(left.composition)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m dims. Received \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m-dim tensor.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    367\u001B[39m left_composition = left.composition\n",
      "\u001B[31mEinopsError\u001B[39m: Wrong shape: expected 5 dims. Received 3-dim tensor.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mEinopsError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m res = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEEGAVI\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/models/single_media_EEGAVI/single_media_EEGAVI.py:110\u001B[39m, in \u001B[36mSingleMediaEEGAVI.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    107\u001B[39m aud_mask = mask[:, order.index(\u001B[33m\"\u001B[39m\u001B[33maud\u001B[39m\u001B[33m\"\u001B[39m)] \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    109\u001B[39m z_kd_vid = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m110\u001B[39m z_vid = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvideo_adapter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvid_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(z_vid, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    112\u001B[39m     z_vid, z_kd_vid = z_vid\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/common/model/embedding/embedder_adapter.py:39\u001B[39m, in \u001B[36mEmbedderAdapter.forward\u001B[39m\u001B[34m(self, x, mask, use_kd)\u001B[39m\n\u001B[32m     36\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     37\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m z = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membedder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m z = \u001B[38;5;28mself\u001B[39m.adapter(z)\n\u001B[32m     42\u001B[39m kd_z: Optional[torch.Tensor] = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/common/model/embedding/predefined/vivit.py:48\u001B[39m, in \u001B[36mViViTFoundationEmbedderForTimeSequences.forward\u001B[39m\u001B[34m(self, x, for_perceiver)\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     46\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.base_model(x.pixel_values)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m x.last_hidden_state = rearrange(x.last_hidden_state, \u001B[33m\"\u001B[39m\u001B[33m(b T) F D -> b T F D\u001B[39m\u001B[33m\"\u001B[39m, b=b)\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.reshape_for_perceiver(x) \u001B[38;5;28;01mif\u001B[39;00m for_perceiver \u001B[38;5;28;01melse\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/einops/einops.py:600\u001B[39m, in \u001B[36mrearrange\u001B[39m\u001B[34m(tensor, pattern, **axes_lengths)\u001B[39m\n\u001B[32m    545\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrearrange\u001B[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001B[38;5;28mstr\u001B[39m, **axes_lengths: Size) -> Tensor:\n\u001B[32m    546\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    547\u001B[39m \u001B[33;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001B[39;00m\n\u001B[32m    548\u001B[39m \u001B[33;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    598\u001B[39m \n\u001B[32m    599\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrearrange\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43maxes_lengths\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/progetto-tesi/.venv/lib/python3.12/site-packages/einops/einops.py:542\u001B[39m, in \u001B[36mreduce\u001B[39m\u001B[34m(tensor, pattern, reduction, **axes_lengths)\u001B[39m\n\u001B[32m    540\u001B[39m     message += \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m Input is list. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    541\u001B[39m message += \u001B[33m\"\u001B[39m\u001B[33mAdditional info: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m.format(axes_lengths)\n\u001B[32m--> \u001B[39m\u001B[32m542\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m EinopsError(message + \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m\"\u001B[39m.format(e))\n",
      "\u001B[31mEinopsError\u001B[39m:  Error while processing rearrange-reduction pattern \"(b T) f c w h -> b T f c w h\".\n Input tensor shape: torch.Size([2, 3137, 768]). Additional info: {'b': 2}.\n Wrong shape: expected 5 dims. Received 3-dim tensor."
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x[0]",
   "id": "264137ab87d70a57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8d353a2401253c52",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
